{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIT742: Modern Data Science \n",
    "**(Assessment Task 01: Wine Rating Data Exploration)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, change and distribute this package.\n",
    "\n",
    "Prepared by **SIT742 Teaching Team**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Student Information:** Please fill your information below\n",
    "\n",
    "- Name: Nnamdi Chukwukelu\n",
    "- Student ID: 217531243\n",
    "- Email: nechukwu@deakin.edu.au\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0. Data Files\n",
    "\n",
    "## 0.1 Download Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\nnamdi chukwukelu\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/wine.json'\n",
    "DataSet = wget.download(link_to_data)\n",
    "\n",
    "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/stopwords.txt'\n",
    "\n",
    "DataSet = wget.download(link_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is TI80187200B\n",
      " Volume Serial Number is D8E8-A278\n",
      "\n",
      " Directory of C:\\Users\\Nnamdi Chukwukelu\\Desktop\\6\\2019 T1\\SIT742- Modern Data Science\\sit742-master\\Assessment\\2019\n",
      "\n",
      "05/04/2019  09:01 PM    <DIR>          .\n",
      "05/04/2019  09:01 PM    <DIR>          ..\n",
      "05/04/2019  08:02 PM    <DIR>          .ipynb_checkpoints\n",
      "27/03/2019  09:53 PM    <DIR>          data\n",
      "05/04/2019  09:01 PM            79,954 SIT742Task1.ipynb\n",
      "05/04/2019  08:02 PM             9,052 SIT742Task2.ipynb\n",
      "04/04/2019  05:43 PM             4,158 stopwords.txt\n",
      "04/04/2019  05:43 PM        79,279,294 wine.json\n",
      "               4 File(s)     79,372,458 bytes\n",
      "               4 Dir(s)  322,622,410,752 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNT3z7_d0E2A"
   },
   "source": [
    "## 0.2 Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuZOT5Uc0E2B"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rykuKlUD0E2E"
   },
   "outputs": [],
   "source": [
    "file = 'wine.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine.json\n"
     ]
    }
   ],
   "source": [
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhSNRInw0E2F",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "pd.read_json('wine.json')\n",
    "wine_data = pd.read_json('wine.json')\n",
    "\n",
    "\n",
    "# read the json file and drop rows with invalid values in the attributes of 'points' and 'price'.\n",
    "df = wine_data\n",
    "import numpy as np\n",
    "\n",
    "df = df[np.isfinite(df['price'])]\n",
    "df = df[np.isfinite(df['points'])]\n",
    "print(type(wine_data))\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-Mn2BCV0E2J"
   },
   "source": [
    "# Part 1: numeric anaysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnyyHM280E2J"
   },
   "source": [
    "## 1.1 Explore the data distribution for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLgAFg_K0E2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country                                        description designation  \\\n",
      "count   120916                                             120975       86196   \n",
      "unique      42                                             111567       35776   \n",
      "top         US  This zesty red has pretty aromas that suggest ...     Reserve   \n",
      "freq     54265                                                  3        1980   \n",
      "mean       NaN                                                NaN         NaN   \n",
      "std        NaN                                                NaN         NaN   \n",
      "min        NaN                                                NaN         NaN   \n",
      "25%        NaN                                                NaN         NaN   \n",
      "50%        NaN                                                NaN         NaN   \n",
      "75%        NaN                                                NaN         NaN   \n",
      "max        NaN                                                NaN         NaN   \n",
      "\n",
      "               points          price    province     region_1       region_2  \\\n",
      "count   120975.000000  120975.000000      120916       101400          50292   \n",
      "unique            NaN            NaN         422         1204             17   \n",
      "top               NaN            NaN  California  Napa Valley  Central Coast   \n",
      "freq              NaN            NaN       36104         4475          10975   \n",
      "mean        88.421881      35.363389         NaN          NaN            NaN   \n",
      "std          3.044508      41.022218         NaN          NaN            NaN   \n",
      "min         80.000000       4.000000         NaN          NaN            NaN   \n",
      "25%         86.000000      17.000000         NaN          NaN            NaN   \n",
      "50%         88.000000      25.000000         NaN          NaN            NaN   \n",
      "75%         91.000000      42.000000         NaN          NaN            NaN   \n",
      "max        100.000000    3300.000000         NaN          NaN            NaN   \n",
      "\n",
      "       taster_name taster_twitter_handle  \\\n",
      "count        96479                 91559   \n",
      "unique          19                    15   \n",
      "top     Roger Voss            @vossroger   \n",
      "freq         20172                 20172   \n",
      "mean           NaN                   NaN   \n",
      "std            NaN                   NaN   \n",
      "min            NaN                   NaN   \n",
      "25%            NaN                   NaN   \n",
      "50%            NaN                   NaN   \n",
      "75%            NaN                   NaN   \n",
      "max            NaN                   NaN   \n",
      "\n",
      "                                                    title     variety  \\\n",
      "count                                              120975      120974   \n",
      "unique                                             110638         697   \n",
      "top     Gloria Ferrer NV Sonoma Brut Sparkling (Sonoma...  Pinot Noir   \n",
      "freq                                                   11       12787   \n",
      "mean                                                  NaN         NaN   \n",
      "std                                                   NaN         NaN   \n",
      "min                                                   NaN         NaN   \n",
      "25%                                                   NaN         NaN   \n",
      "50%                                                   NaN         NaN   \n",
      "75%                                                   NaN         NaN   \n",
      "max                                                   NaN         NaN   \n",
      "\n",
      "            winery  \n",
      "count       120975  \n",
      "unique       15855  \n",
      "top     Testarossa  \n",
      "freq           217  \n",
      "mean           NaN  \n",
      "std            NaN  \n",
      "min            NaN  \n",
      "25%            NaN  \n",
      "50%            NaN  \n",
      "75%            NaN  \n",
      "max            NaN   dtype\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "print(df.describe(include='all'), ('dtype'))\n",
    "# you may use functions such as describe() on each attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8traKPor0E2a"
   },
   "source": [
    "## 1.2 Find the 10 varieties of wine which receives the highest number of  reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTjM_Jmt0E2a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinot Noir                  12787\n",
      "Chardonnay                  11080\n",
      "Cabernet Sauvignon           9386\n",
      "Red Blend                    8476\n",
      "Bordeaux-style Red Blend     5340\n",
      "Riesling                     4972\n",
      "Sauvignon Blanc              4783\n",
      "Syrah                        4086\n",
      "Rosé                         3262\n",
      "Merlot                       3062\n",
      "Name: variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# you may use functions such as value_counts()  \n",
    "top_10= df['variety'].value_counts()\n",
    "print(top_10[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtpXXUrv0E2c"
   },
   "source": [
    "## 1.3 Find varieties of wine having the average price less than 20, with the average pointsat least 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgdpRAfs0E2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          points  price\n",
      "variety                                \n",
      "Blauburgunder               93.0  19.00\n",
      "Caprettone                  92.0  19.00\n",
      "Kotsifali                   92.0  13.00\n",
      "Ondenc                      90.0  15.00\n",
      "Roussanne-Grenache Blanc    91.0  16.00\n",
      "Shiraz-Malbec               90.0  18.67\n",
      "Tinta Cao                   90.0  14.00\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "Avg = df[['variety', 'points', 'price']].groupby('variety').mean().round(decimals = 2)\n",
    "Avg_pr = Avg.loc[Avg['price'] < 20]\n",
    "Avg_pr_pt = Avg_pr.loc[Avg_pr['points'] >= 90]\n",
    "print(Avg_pr_pt)\n",
    "\n",
    "\n",
    "#groupB = df[['country', 'points', 'price']].groupby('country').mean().round(decimals = 2)\n",
    "#statTable = pd.concat([groupA, groupB], axis=1).reset_index()\n",
    "#statTable.columns = ['country', 'variety', 'Av.Points', 'Av.Prices']\n",
    "# you may use functions such as groupby() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yi93saTG0E2i"
   },
   "source": [
    "## 1.4 Build statistic table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPKIEonM0E2j",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   country              variety  Av.Points  Av.Prices\n",
      "0                Argentina               Malbec      86.71      24.51\n",
      "1                  Armenia              Kangoun      87.50      14.50\n",
      "2                Australia           Chardonnay      88.60      35.44\n",
      "3                  Austria     Grüner Veltliner      90.19      30.76\n",
      "4   Bosnia and Herzegovina               Vranec      86.50      12.50\n",
      "5                   Brazil      Sparkling Blend      84.66      23.77\n",
      "6                 Bulgaria                 Rosé      87.94      14.65\n",
      "7                   Canada                Vidal      89.38      35.71\n",
      "8                    Chile  Viognier-Chardonnay      86.50      20.79\n",
      "9                    China       Cabernet Blend      89.00      18.00\n",
      "10                 Croatia             Malvasia      87.35      25.45\n",
      "11                  Cyprus          White Blend      87.18      16.27\n",
      "12          Czech Republic       Welschriesling      87.25      24.25\n",
      "13                 England           Chardonnay      91.55      51.68\n",
      "14                  France       Gewürztraminer      88.73      41.14\n",
      "15                 Georgia             Saperavi      87.68      19.32\n",
      "16                 Germany       Gewürztraminer      89.84      42.26\n",
      "17                  Greece            Assyrtico      87.29      22.36\n",
      "18                 Hungary              Furmint      89.17      40.65\n",
      "19                   India               Shiraz      90.22      13.33\n",
      "20                  Israel                Syrah      88.50      31.77\n",
      "21                   Italy             Frappato      88.62      39.66\n",
      "22                 Lebanon            Red Blend      87.69      30.69\n",
      "23              Luxembourg          White Blend      88.67      23.33\n",
      "24               Macedonia            Sauvignon      86.83      15.58\n",
      "25                  Mexico             Nebbiolo      85.26      26.79\n",
      "26                 Moldova      Feteascǎ Regalǎ      87.20      16.75\n",
      "27                 Morocco                Syrah      88.57      19.50\n",
      "28             New Zealand      Sauvignon Blanc      88.31      26.93\n",
      "29                    Peru               Tannat      83.56      18.06\n",
      "30                Portugal       Portuguese Red      88.32      26.22\n",
      "31                 Romania           Chardonnay      86.40      15.24\n",
      "32                  Serbia               Morava      87.50      24.50\n",
      "33                Slovakia             Riesling      87.00      16.00\n",
      "34                Slovenia      Sauvignon Blanc      88.01      24.81\n",
      "35            South Africa   Cabernet Sauvignon      87.83      24.67\n",
      "36                   Spain   Tempranillo-Merlot      87.29      28.22\n",
      "37             Switzerland     Pinot Noir-Gamay      88.57      85.29\n",
      "38                  Turkey          Papaskarasi      88.09      24.63\n",
      "39                      US           Pinot Gris      88.57      36.57\n",
      "40                 Ukraine      Sparkling Blend      84.07       9.21\n",
      "41                 Uruguay               Tannat      86.75      26.40\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "groupA = df[['country', 'variety']].groupby('country').first()\n",
    "groupB = df[['country', 'points', 'price']].groupby('country').mean().round(decimals = 2)\n",
    "statTable = pd.concat([groupA, groupB], axis=1).reset_index()\n",
    "statTable.columns = ['country', 'variety', 'Av.Points', 'Av.Prices']\n",
    "# you may use functions such as groupby() and round(decimals=2)\n",
    "print(statTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuMzX7100E2l"
   },
   "outputs": [],
   "source": [
    "# save your table to 'statisticByState.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2pM--l1C0E2n"
   },
   "source": [
    "# Part 2. Text Analysis\n",
    "\n",
    "## 2.1 extract high frequency words in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yj_6QJv00E2o"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import *\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhEPsrZi0E2p"
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    stop_words = f.read().splitlines()\n",
    "stop_words = set(stop_words)\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4npAbiy0E2r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'aroma', 'includ', 'tropic', 'fruit', 'broom', 'brimston', '1', 'ripe', 'fruiti', 'wine', 'smooth', '2', 'tart', 'snappi', 'flavor', 'lime', 'flesh', '3', 'pineappl', 'rind', 'lemon', 'pith', 'orang', 'blossom', '4', 'regular', 'bottl', '2012', '5', 'blackberri', 'raspberri', 'aroma', 'show', 'typic', '6', 'bright', 'inform', 'red', 'open', '7', 'dri', 'restrain', 'wine', 'offer', 'spice', '8', 'savori', 'dri', 'thyme', 'note', 'accent', 'sunnier', 'flavor', '9', 'great', 'depth', 'flavor', 'fresh', '10', 'soft', 'suppl', 'plum', 'envelop', 'oaki', 'structur', '11', 'dri', 'wine', 'spici', 'tight', '12', 'slightli', 'reduc', 'wine', 'offer', 'chalki', '13', 'domin', 'oak', 'oak-driven', 'aroma', '14', 'build', '150', 'year', 'gener', '15', 'zesti', 'orang', 'peel', 'appl', 'note', 'abound', '16', 'bake', 'plum', 'molass', 'balsam', 'vinegar']\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "description = wine_data['description'] #extracting description from wine_data\n",
    "description = description.to_string() #conversion of description to string\n",
    "\n",
    "# define your tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\") \n",
    "tokens = tokenizer.tokenize(description) #tokenzaition of description strings\n",
    "tokens = [token.lower() for token in tokens] #mormalizing all to lowercase\n",
    "#print(tokens[:100]) \n",
    "filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "#print(filtered_tokens[:100]) #printing first 100 tokens post-removal of stop words\n",
    "\n",
    "from nltk.stem import PorterStemmer #stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemss = ['{1}'.format(w, stemmer.stem(w)) for w in filtered_tokens]\n",
    "print (stemss[:100]) #priting first 100 stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3Wv41wU0E2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aroma 20130\n",
      "fruit 7021\n",
      "ripe 8027\n",
      "wine 25798\n",
      "nose 5025\n",
      "blend 7428\n",
      "rich 5099\n",
      "['aroma', 'blend', 'fruit', 'nose', 'rich', 'ripe', 'wine']\n"
     ]
    }
   ],
   "source": [
    "# find top common words with document frequencies > 5000\n",
    "frd = FreqDist(stemss)\n",
    "top_words = []\n",
    "for x,y in frd.items():\n",
    "    if y > 5000:\n",
    "        print(x,y)\n",
    "        top_words.append(x)\n",
    "    \n",
    "top_words.sort()\n",
    "print(top_words)\n",
    "# you may use function FreqDist() and sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_0fhtMy0E21"
   },
   "outputs": [],
   "source": [
    "# save your table to 'top_common_words.txt'\n",
    "with open('top_common_words.txt', 'w') as t:\n",
    "    for item in top_words:\n",
    "        t.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rItgiUiW0E22"
   },
   "source": [
    "## 2.2 Find key words for describing Shiraz using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k19yjNax0E23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#select 'description' from 'variety' equal to  'Shiraz' \n",
    "shiraz = wine_data[wine_data.variety == 'Shiraz']\n",
    "shiraz = dict(shiraz['description'])\n",
    "print(type(shiraz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\") \n",
    "\n",
    "shiraz_tokens = {}\n",
    "\n",
    "for x,y in shiraz.items():\n",
    "    new_key = x\n",
    "    new_value = tokenizer.tokenize(str(shiraz.values()))\n",
    "    shiraz_tokens[new_key] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJjSoPYt0E25"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-299-ef7f382118cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshiraz_tokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-299-ef7f382118cd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshiraz_tokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "# use TfidfVectorizer to calculate TF-IDF score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-81TMHm0E29",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-100c42b9b23e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# find words with TF-IDF score >0.4 and sort them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mshiraz_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocabulary_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "# find words with TF-IDF score >0.4 and sort them\n",
    "vocab =tfidf.get_feature_names()\n",
    "shiraz_words = []\n",
    "for word, weight in zip(vocab, tfs.toarray()[0]):\n",
    "    if weight > 0.4:\n",
    "        print(word, \":\", weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkZRD-8j0E3B"
   },
   "outputs": [],
   "source": [
    "# save your table to 'key_Shiraz.txt'   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SIT742Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
